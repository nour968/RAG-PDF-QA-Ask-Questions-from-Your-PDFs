{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13523039,"sourceType":"datasetVersion","datasetId":8586617}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Where is Tips Hindawi University located?\nDoes the university o\n\ner online programs?\nIs there financial aid for international students?\nWhat languages are used for instruction?","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers==4.52.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T15:25:40.430571Z","iopub.execute_input":"2025-11-19T15:25:40.431234Z","iopub.status.idle":"2025-11-19T15:25:43.823560Z","shell.execute_reply.started":"2025-11-19T15:25:40.431207Z","shell.execute_reply":"2025-11-19T15:25:43.822815Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers==4.52.4 in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (3.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.4) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.4) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.52.4) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.4) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.52.4) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.52.4) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.52.4) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.52.4) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install sentence-transformers PyPDF2 faiss-cpu # library from meta to read pdf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T15:25:46.437436Z","iopub.execute_input":"2025-11-19T15:25:46.438060Z","iopub.status.idle":"2025-11-19T15:25:49.805869Z","shell.execute_reply.started":"2025-11-19T15:25:46.438027Z","shell.execute_reply":"2025-11-19T15:25:49.805232Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\nRequirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.13.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install sentence-transformers PyPDF2 faiss-cpu","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\nmodel_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_text(prompt, max_length=100, num_return_sequences=1):\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        num_return_sequences=num_return_sequences,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        temperature=0.7,\n    )\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom PyPDF2 import PdfReader\nimport faiss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_path):\n    reader = PdfReader(pdf_path)\n    full_text = \"\"\n    for page in reader.pages:\n        full_text += page.extract_text() + \"\\n\"\n    return full_text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def chunk_text(text, chunk_size=500, overlap=50):\n    words = text.split()\n    chunks = []\n    for i in range(0, len(words), chunk_size - overlap):\n        chunk = \" \".join(words[i:i + chunk_size])\n        chunks.append(chunk)\n    return chunks","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def embed_chunks(chunks, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n    model = SentenceTransformer(model_name)\n    embeddings = model.encode(chunks, convert_to_numpy=True)\n    return model, embeddings","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_faiss_index(embeddings):\n    dim = embeddings.shape[1] \n    index = faiss.IndexFlatL2(dim) \n    index.add(embeddings) \n    return index","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def search_index(query, model, index, chunks, k=5): \n    query_embedding = model.encode([query], convert_to_numpy=True)\n    distances, indices = index.search(query_embedding, k) \n    return [chunks[i] for i in indices[0]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/dataset/Tips Hindawi University Info.pdf\"  \n\ntext = extract_text_from_pdf(pdf_path) # extract text from psf\nchunks = chunk_text(text,chunk_size=50, overlap=5) #chunk Pdf with overlao 5 words\n\nmodel_embeddings, embeddings = embed_chunks(chunks) # embedding chunks and model\n\nindex = create_faiss_index(embeddings) #create vector database","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(type(index))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"Where is Tips Hindawi University located?\"\ntop_chunks = search_index(question, model_embeddings, index, chunks, k=3)\n\nfor i, chunk in enumerate(top_chunks, 1):\n    print(f\"\\n--- Chunk {i} ---\\n{chunk}\")\n    #return most similar then less similar mesh shart ykono similar blzabt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunk = top_chunks[0]\n#print most one similar \nprompt = f\"Answer the next question: {question} by reading the following text:{chunk}\" \n#give the model mistral the question i write at first and chunk should read return answer from it","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer = generate_text(prompt, max_length=700)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"Does the university offer online programs?\"\ntop_chunks = search_index(question, model_embeddings, index, chunks, k=3)\n\nfor i, chunk in enumerate(top_chunks, 1):\n    print(f\"\\n--- Chunk {i} ---\\n{chunk}\")\n    #return most similar then less similar mesh shart ykono similar blzabt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunk = top_chunks[0]\n#print most one similar \nprompt = f\"Answer the next question: {question} by reading the following text:{chunk}\" \n#give the model mistral the question i write at first and chunk should read return answer from it","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer = generate_text(prompt, max_length=700)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"Is there financial aid for international students?\"\ntop_chunks = search_index(question, model_embeddings, index, chunks, k=3)\n\nfor i, chunk in enumerate(top_chunks, 1):\n    print(f\"\\n--- Chunk {i} ---\\n{chunk}\")\n    #return most similar then less similar mesh shart ykono similar blzabt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunk = top_chunks[0]\n#print most one similar \nprompt = f\"Answer the next question: {question} by reading the following text:{chunk}\" \n#give the model mistral the question i write at first and chunk should read return answer from it","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer = generate_text(prompt, max_length=700)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"What languages are used for instruction?\"\ntop_chunks = search_index(question, model_embeddings, index, chunks, k=3)\n\nfor i, chunk in enumerate(top_chunks, 1):\n    print(f\"\\n--- Chunk {i} ---\\n{chunk}\")\n    #return most similar then less similar mesh shart ykono similar blzabt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chunk = top_chunks[0]\n#print most one similar \nprompt = f\"Answer the next question: {question} by reading the following text:{chunk}\" \n#give the model mistral the question i write at first and chunk should read return answer from it","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer = generate_text(prompt, max_length=700)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(answer[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install pyngrok\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T15:26:27.399163Z","iopub.execute_input":"2025-11-19T15:26:27.400052Z","iopub.status.idle":"2025-11-19T15:26:30.606987Z","shell.execute_reply.started":"2025-11-19T15:26:27.400008Z","shell.execute_reply":"2025-11-19T15:26:30.606082Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.5.0)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.3)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"NGROK_TOKEN = \"35f7eKk4dud8PxL7IPbSrLXpOQB_4aEX5ygh5ZF5r7jtxZvcd\"\nAPI_KEY = \"secret123\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T15:29:08.267672Z","iopub.execute_input":"2025-11-19T15:29:08.268412Z","iopub.status.idle":"2025-11-19T15:29:08.271737Z","shell.execute_reply.started":"2025-11-19T15:29:08.268385Z","shell.execute_reply":"2025-11-19T15:29:08.271058Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\n\nmodel_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T15:26:36.311992Z","iopub.execute_input":"2025-11-19T15:26:36.312603Z","iopub.status.idle":"2025-11-19T15:28:22.535308Z","shell.execute_reply.started":"2025-11-19T15:26:36.312580Z","shell.execute_reply":"2025-11-19T15:28:22.534403Z"}},"outputs":[{"name":"stderr","text":"2025-11-19 15:26:45.012462: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763566005.045557     289 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763566005.053726     289 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5edd3ebec77415f92b38169ea8189e5"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from fastapi import FastAPI, HTTPException, UploadFile, File, Form\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom sentence_transformers import SentenceTransformer\nfrom PyPDF2 import PdfReader\nimport faiss\nimport torch\nimport shutil\nimport os\n\napp = FastAPI()\n\n# -----------------------------\n# Utility Functions\n# -----------------------------\ndef extract_text_from_pdf(pdf_path):\n    reader = PdfReader(pdf_path)\n    full_text = \"\"\n    for page in reader.pages:\n        full_text += page.extract_text() + \"\\n\"\n    return full_text\n\ndef chunk_text(text, chunk_size=500, overlap=50):\n    words = text.split()\n    chunks = []\n    for i in range(0, len(words), chunk_size - overlap):\n        chunk = \" \".join(words[i:i + chunk_size])\n        chunks.append(chunk)\n    return chunks\n    \ndef embed_chunks(chunks, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n    model = SentenceTransformer(model_name)\n    embeddings = model.encode(chunks, convert_to_numpy=True)\n    return model, embeddings\n\ndef create_faiss_index(embeddings):\n    dim = embeddings.shape[1] \n    index = faiss.IndexFlatL2(dim) \n    index.add(embeddings) \n    return index\n    \ndef search_index(query, model, index, chunks, k=5): \n    query_embedding = model.encode([query], convert_to_numpy=True)\n    distances, indices = index.search(query_embedding, k) \n    return [chunks[i] for i in indices[0]]\n    \ndef generate_text(prompt, max_length=100, num_return_sequences=1):\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    outputs = model.generate(\n        **inputs,\n        max_length=max_length,\n        num_return_sequences=num_return_sequences,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        temperature=0.7,\n    )\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n\n# -----------------------------\n# FastAPI Endpoint\n# -----------------------------\n@app.post(\"/rag\")\nasync def rag_endpoint(question: str = Form(...), file: UploadFile = File(...)):\n    try:\n        # Save uploaded file temporarily\n        temp_path = f\"/tmp/{file.filename}\"\n        with open(temp_path, \"wb\") as buffer:\n            shutil.copyfileobj(file.file, buffer)\n\n        # 1. Extract text\n        text = extract_text_from_pdf(temp_path)\n\n        # 2. Chunk text\n        chunks = chunk_text(text,chunk_size=50, overlap=5)\n        # 3. embedding chunks\n        model_embeddings, embeddings = embed_chunks(chunks)\n\n        # 4. create database\n        index = create_faiss_index(embeddings)\n\n        # 5. Generate answer\n        top_chunks = search_index(question, model_embeddings, index, chunks, k=3)\n        chunk = top_chunks[0]\n        prompt = f\"Answer the next question: {question} by reading the following text:{chunk}\" \n        answer = generate_text(prompt, max_length=700)\n       \n        return {\n            \"question\": question,\n            \"retrieved_chunks\": chunk,\n            \"answer\": answer[0]\n        }\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T15:49:48.972370Z","iopub.execute_input":"2025-11-19T15:49:48.973192Z","iopub.status.idle":"2025-11-19T15:49:48.986205Z","shell.execute_reply.started":"2025-11-19T15:49:48.973163Z","shell.execute_reply":"2025-11-19T15:49:48.985448Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import uvicorn, threading, time, socket\nfrom pyngrok import ngrok, conf\ndef free_port():\n    s = socket.socket()\n    s.bind(('', 0))\n    port = s.getsockname()[1]\n    s.close()\n    return port\n\nport = free_port()\nconf.get_default().auth_token = NGROK_TOKEN #put token of ngrok\npublic_url = ngrok.connect(port).public_url\nprint(\"Your public URL:\", public_url)\n\ndef run(): uvicorn.run(app, host=\"0.0.0.0\", port=port)\nthreading.Thread(target=run, daemon=True).start()\ntime.sleep(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T16:01:40.260728Z","iopub.execute_input":"2025-11-19T16:01:40.261426Z","iopub.status.idle":"2025-11-19T16:01:41.492110Z","shell.execute_reply.started":"2025-11-19T16:01:40.261396Z","shell.execute_reply":"2025-11-19T16:01:41.491494Z"}},"outputs":[{"name":"stdout","text":"Your public URL: https://apprehensibly-cresylic-layla.ngrok-free.dev\n","output_type":"stream"},{"name":"stderr","text":"INFO:     Started server process [289]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://0.0.0.0:54465 (Press CTRL+C to quit)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cec8627a3274d76b483bc75233932c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18cc2584d38f4c6c9c7f3537041eb6fa"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     62.139.111.70:0 - \"POST /rag HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e785dcb7775496b862a722d5967dbf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e608a4cda8b4c6887e33e2b4f961223"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     62.139.111.70:0 - \"POST /rag HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127d4177e8f4453fbc67c2494c1e78fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ca1509590594a24a8f8f72af4026130"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     62.139.111.70:0 - \"POST /rag HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e25440ee911d4471905a6dc56f297b75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cbc1a24ba884d80af9fab709a428709"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     62.139.111.70:0 - \"POST /rag HTTP/1.1\" 200 OK\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c76a7125bcd445e9dc642c6c318e7ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a9ffaccd2174db28219bcd0bfb74506"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     62.139.111.70:0 - \"POST /rag HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import requests\n\nURL = \"https://apprehensibly-cresylic-layla.ngrok-free.dev/rag\"\nAPI_KEY = \"secret123\"\n\n# Question\nquestion = \"Does Tips Hindawi University have online programs?\"\n\n# Path to the local PDF file\nfile_path = \"/kaggle/input/dataset/Tips Hindawi University Info.pdf\"\n\n# Prepare multipart form data\nfiles = {\n    \"file\": (file_path.split(\"/\")[-1], open(file_path, \"rb\"), \"application/pdf\")\n}\ndata = {\n    \"question\": question\n}\nheaders = {\n    \"Authorization\": f\"Bearer {API_KEY}\"\n}\n\n# Send request\nresponse = requests.post(URL, headers=headers, data=data, files=files)\n\n# Handle response\nif response.status_code == 200:\n    result = response.json()\n    print(\"Question:\", result['question']+\"\\n\",result['answer'])\nelse:\n    print(\"Error:\", response.status_code, response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T15:50:36.534196Z","iopub.execute_input":"2025-11-19T15:50:36.534774Z","iopub.status.idle":"2025-11-19T15:51:43.584780Z","shell.execute_reply.started":"2025-11-19T15:50:36.534744Z","shell.execute_reply":"2025-11-19T15:51:43.584033Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d0760610240430096f3adb01aabee17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97e8fa41b1f34f62b80f62b0d20cfb9d"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     34.170.240.255:0 - \"POST /rag HTTP/1.1\" 200 OK\nINFO:     34.170.240.255:0 - \"POST /rag HTTP/1.1\" 200 OK\nQuestion: Does Tips Hindawi University have online programs?\n Answer Answer the next question: Does Tips Hindawi University have online programs? by reading the following text:1. General Overview Tips Hindawi University (THU) is a premier institution of higher education located in the heart of the Middle East. Founded in 1963, the university has grown into a globally recognized center for academic excellence and innovation. With over six decades of educational leadership, THU has produced more than 250,000 graduates who have made significant contributions to their communities and fields of expertise.\n\n2. Academic Programs\nTHU offers a wide range of academic programs, spanning over 180 majors and minors across 16 colleges and schools. These programs are designed to equip students with the knowledge and skills needed to thrive in today's rapidly changing world. The university's academic offerings include:\n\n   a. Undergraduate Programs: THU provides a robust selection of bachelor's degree programs in arts, sciences, engineering, medicine, law, and more. These programs are designed to give students a strong foundation in their chosen field of study.\n\n   b. Graduate Programs: The university offers a diverse range of master's and doctoral degree programs, allowing students to specialize in their chosen field and conduct advanced research. These programs are taught by leading experts in their fields and provide students with the opportunity to contribute to original research.\n\n   c. Online Programs: THU is committed to providing accessible education to students worldwide. To this end, the university offers a growing selection of online programs, allowing students to pursue their academic goals from anywhere in the world. These online programs are taught by the same faculty who teach on-campus courses and provide students with the same high-quality education.\n\n3. Research and Innovation\nTHU is deeply committed to research and innovation, with a strong emphasis on interdisciplinary collaboration. The university is home to numerous research centers and institutes, which conduct cutting-edge research in fields such as renewable energy, nanotechnology, and artificial intelligence. THU's research efforts have resulted in numerous patents, publications, and collaborations with industry partners.\n\n4. Campus Life\nTHU's main campus is located in the vibrant city of Dubai, offering students a dynamic and multicultural environment in which to live and learn. The campus features modern facilities, including state-of-the-art classrooms, laboratories, and libraries, as well as a range of recreational and athletic facilities. THU also offers a variety of student services, including academic support, career guidance, and health and wellness resources.\n\n5. Global Engagement\nTHU is deeply committed to global engagement, with a network of over 400 partner institutions worldwide. The university offers a range of study abroad and exchange programs, allowing students to gain international experience and broaden their perspectives. THU also hosts a diverse international student body, with students from over 150 countries represented on campus.\n\nIn summary, Tips Hindawi University is a comprehensive institution of higher education that offers a wide range of academic programs, a strong commitment to research and innovation, and a vibrant campus life. With its global engagement and commitment to accessible education, THU is a leader in higher education in the Middle East and beyond.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e614e3853808467d92ee7052a54ba059"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef4ea6eba58f48ca8f6fefa232208493"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"INFO:     62.139.111.70:0 - \"POST /rag HTTP/1.1\" 200 OK\n","output_type":"stream"}],"execution_count":26}]}